---
title:  "[NLP] "
excerpt: ""

categories:
  - ml
tags:
  - [nlp]

toc: true
toc_sticky: true
use_math: true
 
date: 2022-05-04
last_modified_at: 2022-05-06
---


### 텍스트 분석 패키지

- NLTK
- Gensim
- SpaCy

### Text preprocessing

- Cleansing: HTML, XML 태그 제거
- Tokenization
  - 문장 토큰화
  - 단어 토큰화
  - n-gram
- 필터링/스톱워드 제거/철자 수정
  -불필요한 단어나 분석에 큰 의미가 없는 단어(관사, 조동사) 제거  
- Stemming/Lemmatization
  - 어근 추출

- Filtering/Stop word

#### N-gram

단어를 개별 단어로 토큰화하면 문맥적인 의미가 무시되는데 이를 해결하기 위해  
Agent Smith knocks the door  

3-gram  
`Agent Smith knocks` `Smth knocks the` `knocks the door`  

## Text to Vector(Feature Vectorization)

### Bag of Words

단어들의 횟수나 정규화 반환된 횟수로 표현  
문맥이나 순서는 무시하고 일괄적으로 단어에 대해 빈도 값을 부여해 피처 값을 추출  

#### 장점
- 쉽고 빠른 구축
- 예상보다 문서의 특징을 잘 나타내어 전통적으로 많이 활용 됨

#### 단점
- 문맥 의미를 반영할 수 없다
- 희소 행렬 문제

#### BOW 유형
- 단순 카운트 기반의 벡터화
- TF-IDF 벡터화(Term Frequency - Inverse Document Frequence)
  - 개별 문서에서 자주 나타나는 단어에 가중치를 주고
  - 모든 문서 전반적에 걸쳐 자주 나타나는 단어에는 패널티를 준다
  - 한 문서에서만 나타나는 단어는 중요한 단어다
  - *TF*: 문서에서 해당 단어가 얼마나 나왔는지
  - *DF*: 해당 단어가 몇 개의 문서에서 나왔는지
  - *IDF*: DF의 역수(=$\frac{전체문서수}{DF}$)
  - $TFIDF_{i} = TF * log(\frac{N}{DF_{i}})$

stop_words: 지정된 단어는 추출하지 않음  

### Word Embedding(Word2Vec)

### 희소행렬

- COO: 0이 아닌 값의 인덱스로 나타냄
- CSR: 

## 뉴스 분류

텍스트 정규화 - 피처 벡터화 - 학습/평가 - 파이프라인 적용 - 그리드서치CV  

