---
title:  "[quest] ch.2"
excerpt: ""

categories:
  - ml
tags:
  - [quest]

toc: true
toc_sticky: true

use_math: true
date: 2022-04-26
last_modified_at: 2022-04-26
---

## 평가 지표의 한계

### Accuracy

negative sample이 전체에서 차지하는 양이 많으면 항상 negative로 예측해도 높은 정확도를 가짐
> 즉, 항상 눈이 오는 것을 False로 예측하면, 이는 높은 accuracy를 가질 것

### precision, recall

#### precision

예측한 것 중에 정답의 비율?

#### recall

찾아야 할 것 중에 실제로 찾은 비율?

#### F1

정밀도와 재현율의 조화 평균

## ROC 곡선

$$
    FPR = \frac{FP}{N}
$$

$$
    TPR = \frac{TP}{P}
$$

## Consine Distance

## A/B 테스트의 함정

## 모델 평가 방법

## 데이터파라미터 튜닝

## Over-Fitting, Under-Fitting

### Over-Fitting

- 더 많은 데이터 확보
- 모델의 복잡도 낮추기
- 정규화 사용
- 앙상블 학습 방법 사용
  - Bagging
    
### Under-Fitting

- 새로운 특성을 추가
- 모델의 복ㅈ바도 증가
- 정규화 계수를 줄이기

Refer to [Learning Curve](../hands-on/2022-04-26-hands-on-ml-ch4-training-models.md#over-fitting-under-fitting)
